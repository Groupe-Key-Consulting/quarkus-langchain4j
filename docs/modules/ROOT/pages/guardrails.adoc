= Guardrails - Controlling the Chaos

Guardrails are mechanisms that let you validate the output of the LLM to ensure it meets your expectations.
Typically, you can:

- Ensure that the format is correct (e.g., it is a JSON document with the right schema)
- Detect hallucinations (especially in the context of a RAG)

NOTE: At the moment, Quarkus Langchain4J only offers output guardrails.
Input guardrails are not yet implemented but are planned.

image::guardrails.png[width=600,align="center"]

== Implementing Output Guardrails

Output guardrails are _functions_ invoked once the LLM has produced its output.
They are implemented as CDI beans and must implement the `io.quarkiverse.langchain4j.guardrails.OutputGuardrail` interface:

[source,java]
----
package io.quarkiverse.langchain4j.guardrails;

import dev.langchain4j.data.message.AiMessage;
import dev.langchain4j.memory.ChatMemory;
import dev.langchain4j.rag.AugmentationResult;

/**
 * A guardrail is a rule that is applied to the output of the model to ensure that the output is safe and meets the
 * expectations.
 * <p>
 * Implementation should be exposed as a CDI bean, and the class name configured in {@link OutputGuardrails#value()} annotation.
 * <p>
 * Implementation should throw a {@link ValidationException} when the validation fails. The exception can indicate whether the
 * request should be retried and provide a {@code reprompt} message.
 * In the case of reprompting, the reprompt message is added to the LLM context and the request is retried.
 * <p>
 * The maximum number of retries is configurable using {@code quarkus.langchain4j.guardrails.max-retries}, defaulting to 3.
 */
public interface OutputGuardrail {

    /**
     * Validates the response from the LLM.
     * <p>
     * If the validation fails with an exception that is not a {@link ValidationException}, no retry will be attempted.
     *
     * @param responseFromLLM the response from the LLM
     * @throws ValidationException the exception throws if the validation fails.
     */
    default void validate(AiMessage responseFromLLM) throws ValidationException {
        throw new ValidationException("Validation not implemented", false, null);
    }

    /**
     * Validates the response from the LLM.
     * <p>
     * Unlike {@link #validate(AiMessage)}, this method allows to access the memory and the augmentation result (in the
     * case of a RAG).
     * <p>
     * If the validation fails with an exception that is not a {@link ValidationException}, no retry will be attempted.
     * <p>
     * Implementation must not attempt to write to the memory or the augmentation result.
     *
     * @param params the parameters, including the response from the LLM, the memory (maybe null),
     *        and the augmentation result (maybe null). Cannot be {@code null}
     * @throws ValidationException the exception throws if the validation fails.
     */
    default void validate(OutputGuardrailParams params)
            throws ValidationException {
        validate(params.responseFromLLM());
    }

    /**
     * Represents the parameter passed to {@link #validate(OutputGuardrailParams)}.
     *
     * @param responseFromLLM the response from the LLM
     * @param memory the memory, can be {@code null} or empty
     * @param augmentationResult the augmentation result, can be {@code null}
     */
    record OutputGuardrailParams(AiMessage responseFromLLM, ChatMemory memory, AugmentationResult augmentationResult) {
    }

}

----

The `validate` method of the `OutputGuardrail` interface can have two signatures:

- `void validate(AiMessage responseFromLLM) throws ValidationException`
- `void validate(OutputGuardrailParams params) throws ValidationException`

The first one is used when the guardrail only needs the output of the LLM.
Simple guardrails can use this method.
For example, here is an output guardrail that checks that the output is a JSON document:

[source,java]
----
import com.fasterxml.jackson.databind.ObjectMapper;
import dev.langchain4j.data.message.AiMessage;
import io.quarkiverse.langchain4j.guardrails.OutputGuardrail;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;

@ApplicationScoped
public class JsonGuardrail implements OutputGuardrail {

    @Inject
    ObjectMapper mapper;

    @Override
    public void validate(AiMessage responseFromLLM) throws ValidationException {
        try {
            mapper.readTree(responseFromLLM.text());
        } catch (Exception e) {
            throw new ValidationException("Invalid JSON", true, "Make sure you return a valid JSON object");
        }
    }

}
----

The second signature is used when the guardrail needs more information, like the augmentation results or the memory.
Note that the guardrail cannot modify the memory or the augmentation results.
The <<_detecting_hallucinations_in_the_rag_context>> section gives an example of guardrail using the augmented results.

=== Output Guardrails Outcome

Output guardrails can have four outcomes:

- _pass_ - The output is valid, the next guardrail is executed, and if the last guardrail passes, the output is returned to the caller.
- _fail_ - The output is invalid, the next guardrail is **not** executed, and the error is rethrown.
- _fail with retry_ - The output is invalid, the next guardrail is **not** executed, and the LLM is called again with the **same** prompt.
- _fail with reprompt_ - The output is invalid, the next guardrail is **not** executed, and the LLM is called again with a **new** prompt.

A `validate` method completing successfully is considered a pass.
A `validate` method throwing an `Exception` is considered a fail.
If that exception is a `io.quarkiverse.langchain4j.guardrails.OutputGuardrail.ValidationException` exception, then the guardrail can specify whether the LLM should be retried or reprompted.

[source,java]
----
// Retry - The LLM is called again with the same prompt and context
// The guardrails will be called again with the new output
throw new ValidationException("Invalid JSON", true, null);

// Retry with reprompt - The LLM is called again with a new prompt and context
// A new user message is added to the LLM context (memory), and the LLM is called again with this new context.
// The guardrails will be called again with the new output
throw new ValidationException("Invalid JSON", true, "Make sure you return a valid JSON object");
----

IMPORTANT: _Reprompting_ requires the `retry` parameter to be set to `true` in the `ValidationException` constructor.

By default, Quarkus Langchain4J will limit the number of retries to 3.
This is configurable using the `quarkus.langchain4j.guardrails.max-retries` configuration property:

[source,properties]
----
quarkus.langchain4j.guardrails.max-retries=5
----

NOTE: Setting `quarkus.langchain4j.guardrails.max-retries` to 0 disables retries.

=== Output Guardrails Scopes

Output guardrails are CDI beans.
They can be in any CDI scope, including request scope, application scope, or session scope.

The scope of the guardrail is important as it defines the lifecycle of the guardrail, especially when the guardrail is stateful.

== Declaring Output Guardrails

Output guardrails are declared on the AI Service interface. You can declare output guardrails in two ways:

- By annotating the AI Service interface with `@OutputGuardrails` and listing the guardrails - these guardrails will be applied to all the methods of the AI Service.
- By annotating the method of the AI Service with `@OutputGuardrails` and listing the guardrails - these guardrails will be applied to this method only.

NOTE: Method guardrails take precedence over class guardrails.

Here is an example of an AI Service interface with output guardrails:

[source,java]
----
import dev.langchain4j.service.SystemMessage;
import io.quarkiverse.langchain4j.RegisterAiService;
import io.quarkiverse.langchain4j.guardrails.OutputGuardrails;
import jakarta.enterprise.context.SessionScoped;

@RegisterAiService(retrievalAugmentor = Retriever.class)
@SystemMessage("""
    You are Mona, a chatbot answering questions about a museum. Be polite, concise, and helpful.
""")
@SessionScoped
public interface ChatBot {

    @OutputGuardrails(HallucinationGuard.class)
    String chat(String question);

}
----

=== Guardrail Chain

You can declare multiple guardrails.
In this case, a chain is created, and the guardrails are executed in the order they are declared.
Thus, the order of the guardrails is important.

Typically, it's a good idea to have a guardrail that checks the format of the output first, and then a guardrail that checks the content.

[source,java]
----
@RegisterAiService
@SystemMessage("""
    You are simulating fights between a superhero and a supervillain.
""")
public interface Simulator {

    @UserMessage("""
        Simulate a fight between:
        - a hero: {hero}
        - a villain: {villain}
    """)
    @OutputGuardrails({JsonGuardrail.class, ConsistentStoryGuardrail.class})
    FightResult fight(Hero hero, Villain villain);

}
----

In this example, the `JsonGuardrail` is executed first to check that the output is a valid JSON document.
Then, the `ConsistentStoryGuardrail` is executed to check that the story is consistent.

If the `JsonGuardrail` fails, the `ConsistentStoryGuardrail` is not executed.
However, if the `ConsistentStoryGuardrail` fails with a retry or reprompt, the `JsonGuardrail` is executed again with the new response.

[#_detecting_hallucinations_in_the_rag_context]
== Detecting Hallucinations in the RAG Context

This section is an example of how to implement a guardrail that detects hallucinations in the context of a RAG.
The idea is to check that the output of the LLM is consistent with the augmentation results.

[source,java]
----
package me.escoffier.langchain4j.nomic;

import dev.langchain4j.data.embedding.Embedding;
import dev.langchain4j.model.output.Response;
import dev.langchain4j.rag.content.Content;
import io.quarkiverse.langchain4j.guardrails.OutputGuardrail;
import io.quarkus.logging.Log;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.eclipse.microprofile.config.inject.ConfigProperty;

@ApplicationScoped
public class HallucinationGuard implements OutputGuardrail {

    @Inject
    NomicEmbeddingV1 embedding;

    @ConfigProperty(name = "hallucination.threshold", defaultValue = "0.7")
    double threshold;

    @Override
    public void validate(OutputGuardrailParams params) throws ValidationException {
        Response<Embedding> embeddingOfTheResponse = embedding.embed(params.responseFromLLM().text());
        if (params.augmentationResult() == null || params.augmentationResult().contents().isEmpty()) {
            Log.info("No content to validate against");
            return;
        }
        float[] vectorOfTheResponse = embeddingOfTheResponse.content().vector();
        for (Content content : params.augmentationResult().contents()) {
            Response<Embedding> embeddingOfTheContent = embedding.embed(content.textSegment());
            float[] vectorOfTheContent = embeddingOfTheContent.content().vector();
            double distance = cosineDistance(vectorOfTheResponse, vectorOfTheContent);
            if (distance < threshold) {
                Log.info("Passed hallucination guardrail: " + distance);
                return;
            }
        }

        throw new ValidationException("Hallucination detected", true, "Make sure you use the given documents to produce the response");
    }

    public static double cosineDistance(float[] vector1, float[] vector2) {
        double dotProduct = 0.0;
        double normA = 0.0;
        double normB = 0.0;

        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            normA += Math.pow(vector1[i], 2);
            normB += Math.pow(vector2[i], 2);
        }

        double cosineSimilarity = dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
        return 1.0 - cosineSimilarity;
    }
}
----